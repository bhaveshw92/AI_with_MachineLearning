# Natural Language Processing (NLP) Lab and Lecture Notes

This repository contains lab exercises and lecture materials focusing on Word2Vec, word embeddings, and neural networks. The resources explore how to use pre-trained models and visualization techniques to represent word meanings and how neural networks contribute to NLP tasks.

## Contents

1. **Lab5_Word2Vec_using_Gensim.ipynb**
2. **Lab5_word_vectors_visualization.ipynb**
3. **Lecture_5_NeuralNetworks_DeepLearning.pdf**

---

## 1. Lab5_Word2Vec_using_Gensim.ipynb

### Overview

This notebook demonstrates how to use the Gensim library to create Word2Vec word embeddings from a text corpus. It shows the process of training a Word2Vec model and extracting meaningful word representations.

### Key Features

- **Word2Vec Training**: Trains a Word2Vec model using the Gensim library on a sample corpus.
- **Word Embeddings**: Generates vector representations for words based on their context within sentences.
- **Model Evaluation**: Evaluates the word embeddings by finding similar words and performing basic similarity tasks.

### How to Run

Run the notebook `Lab5_Word2Vec_using_Gensim.ipynb` in Jupyter to train the Word2Vec model and explore word embeddings.

---

## 2. Lab5_word_vectors_visualization.ipynb

### Overview

This notebook provides visualization techniques for word vectors. It uses dimensionality reduction techniques like PCA and t-SNE to project word embeddings into 2D or 3D space for better understanding of the relationships between words.

### Key Features

- **Dimensionality Reduction**: Applies PCA and t-SNE to reduce the dimensionality of word vectors.
- **Visualization**: Projects word vectors into a 2D or 3D space to visualize the similarity between words.
- **Word Similarity**: Visualizes how similar words cluster together based on their embeddings.

### How to Run

Run the notebook `Lab5_word_vectors_visualization.ipynb` in Jupyter to visualize word vectors and their relationships in a reduced-dimensional space.

---

## 3. Lecture_5_NeuralNetworks_DeepLearning.pdf

### Overview

This lecture covers the fundamentals of neural networks and deep learning, focusing on how these models are used in NLP tasks like Word2Vec and GloVe. It introduces the architecture of neural networks and explains the key concepts behind feedforward networks and word embeddings.

### Key Topics

- **Neural Networks**: Understanding feedforward networks and their application to NLP.
- **Word2Vec & GloVe**: Introduction to word embeddings and how neural networks are used to generate these embeddings.
- **Deep Learning**: Discusses deep learning architectures and their role in representing complex language structures.

### How to Use

Read `Lecture_5_NeuralNetworks_DeepLearning.pdf` for a comprehensive overview of neural networks, deep learning, and word embeddings like Word2Vec and GloVe.

---
