{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6ab295f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ab295f0",
        "outputId": "e0e3c63f-b444-4947-8d85-86578d15ddb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14750d27",
      "metadata": {
        "id": "14750d27"
      },
      "source": [
        "### Named Entity Extraction in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c73c8826",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c73c8826",
        "outputId": "1aef2b7e-d7f2-4463-ee42-7400b9f4223a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('NASA', 'NNP'), ('awarded', 'VBD'), ('Elon', 'NNP'), ('Musk', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('SpaceX', 'NNP'), ('a', 'DT'), ('$', '$'), ('2.9', 'CD'), ('billion', 'CD'), ('contract', 'NN'), ('to', 'TO'), ('build', 'VB'), ('the', 'DT'), ('lunar', 'NN'), ('lander', 'NN'), ('.', '.')]\n",
            "(S\n",
            "  (ORGANIZATION NASA/NNP)\n",
            "  awarded/VBD\n",
            "  (PERSON Elon/NNP Musk/NNP)\n",
            "  ’/NNP\n",
            "  s/VBD\n",
            "  (ORGANIZATION SpaceX/NNP)\n",
            "  a/DT\n",
            "  $/$\n",
            "  2.9/CD\n",
            "  billion/CD\n",
            "  contract/NN\n",
            "  to/TO\n",
            "  build/VB\n",
            "  the/DT\n",
            "  lunar/NN\n",
            "  lander/NN\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "# The following code will convert each word into a token and it would pass to pos_tag function which will tag each token and print them.\n",
        "# The nltk.ne_chunk() function that is already a pre-trained classifier will recognize the named entity using POS tag done above.\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "from nltk import word_tokenize,pos_tag\n",
        "\n",
        "text = \"NASA awarded Elon Musk’s SpaceX a $2.9 billion contract to build the lunar lander.\"\n",
        "tokens = word_tokenize(text)\n",
        "tag=pos_tag(tokens)\n",
        "print(tag)\n",
        "\n",
        "ne_tree = nltk.ne_chunk(tag)\n",
        "print(ne_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57fcc092",
      "metadata": {
        "id": "57fcc092"
      },
      "source": [
        "Observation: In the above text provided as input to the POS_tag function has correctly identified the Organization NASA and SpaceX, the Person as Elon Musk and other details $ and 2.9 currency which is preety descent tagging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5cb3050c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cb3050c",
        "outputId": "e70b4b71-e12c-47d0-b8b0-36961c8b1d12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('treebank')\n",
        "sent = nltk.corpus.treebank.tagged_sents()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "13c8bac0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13c8bac0",
        "outputId": "b1060418-8aa5-4026-a137-ba5b3431314d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (PERSON Pierre/NNP)\n",
            "  (ORGANIZATION Vinken/NNP)\n",
            "  ,/,\n",
            "  61/CD\n",
            "  years/NNS\n",
            "  old/JJ\n",
            "  ,/,\n",
            "  will/MD\n",
            "  join/VB\n",
            "  the/DT\n",
            "  board/NN\n",
            "  as/IN\n",
            "  a/DT\n",
            "  nonexecutive/JJ\n",
            "  director/NN\n",
            "  Nov./NNP\n",
            "  29/CD\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "print(nltk.ne_chunk(sent[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e116b843",
      "metadata": {
        "id": "e116b843"
      },
      "source": [
        "Observation: In this case using ne_chunk the predefined sentence was also tag well, with Pierre as Person, Vinken as Organization, 61 and 29 as CD."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f5b68a1",
      "metadata": {
        "id": "5f5b68a1"
      },
      "source": [
        "### NER using Sapcy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e5b74007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5b74007",
        "outputId": "62dfd9da-087a-4b77-9888-3d94dfe3c162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "# Install the required spacy dependency\n",
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d661ea53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d661ea53",
        "outputId": "44882353-7c1c-48d6-e9b8-c395ab3561a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "# Upgrade the typing-extensions and spacy\n",
        "!pip install --upgrade typing-extensions\n",
        "!pip install --upgrade spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f4d14ebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4d14ebf",
        "outputId": "0a29c842-e097-4807-96d6-b215ccf27938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NASA B ORG\n",
            "awarded O \n",
            "Elon B PERSON\n",
            "Musk I PERSON\n",
            "’s I PERSON\n",
            "SpaceX O \n",
            "a O \n",
            "$ B MONEY\n",
            "2.9 I MONEY\n",
            "billion I MONEY\n",
            "contract O \n",
            "to O \n",
            "build O \n",
            "the O \n",
            "lunar O \n",
            "lander O \n",
            ". O \n"
          ]
        }
      ],
      "source": [
        "# The following code will perform the tokenization and print the token entity annotations, and the entity types of the token.\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"NASA awarded Elon Musk’s SpaceX a $2.9 billion contract to build the lunar lander.\")\n",
        "for token in doc:\n",
        "    print(token.text, token.ent_iob_, token.ent_type_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XBVsjKAlcn9A",
      "metadata": {
        "id": "XBVsjKAlcn9A"
      },
      "source": [
        "## **Exercise 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d9d86482",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9d86482",
        "outputId": "38271ca3-663b-4571-ed0d-5e219c58cd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Ahimsa', 'NNP'), ('paramo', 'NN'), ('dharmaha', 'NN'), ('’', 'NNP'), ('–', 'NNP'), ('Non-violence', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('highest', 'JJS'), ('ethical', 'JJ'), ('code', 'NN'), ('laid', 'VBD'), ('down', 'RB'), ('in', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('shastras', 'NNS'), ('.', '.'), ('No', 'DT'), ('one', 'NN'), ('should', 'MD'), ('harm', 'VB'), ('any', 'DT'), ('creature', 'NN'), ('by', 'IN'), ('body', 'NN'), (',', ','), ('mind', 'NN'), ('or', 'CC'), ('speech', 'NN'), (';', ':'), ('nor', 'CC'), ('should', 'MD'), ('anyone', 'NN'), ('intentionally', 'RB'), ('kill', 'VB'), ('insects', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('lice', 'NN'), (',', ','), ('bugs', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), ('Even', 'RB'), ('for', 'IN'), ('the', 'DT'), ('purpose', 'NN'), ('of', 'IN'), ('performing', 'VBG'), ('yagnas', 'NNS'), (',', ','), ('none', 'NN'), ('should', 'MD'), ('kill', 'VB'), ('animals', 'NNS'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('because', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('sin', 'NN'), ('to', 'TO'), ('kill', 'VB'), ('animals', 'NNS'), ('and', 'CC'), ('offer', 'VB'), ('them', 'PRP'), ('as', 'IN'), ('sacrifices', 'NNS'), ('.', '.'), ('Shriji', 'NNP'), ('Maharaj', 'NNP'), ('even', 'RB'), ('refused', 'VBD'), ('to', 'TO'), ('pluck', 'VB'), ('spinach', 'NN'), ('leaves', 'NNS'), ('in', 'IN'), ('Jagannathpuri', 'NNP'), ('on', 'IN'), ('the', 'DT'), ('grounds', 'NNS'), ('that', 'IN'), ('it', 'PRP'), ('also', 'RB'), ('has', 'VBZ'), ('life', 'NN'), ('.', '.'), ('Even', 'RB'), ('for', 'IN'), ('women', 'NNS'), (',', ','), ('wealth', 'NN'), ('or', 'CC'), ('kingdom', 'NN'), (',', ','), ('one', 'CD'), ('should', 'MD'), ('never', 'RB'), (',', ','), ('in', 'IN'), ('any', 'DT'), ('way', 'NN'), (',', ','), ('harm', 'NN'), ('or', 'CC'), ('kill', 'VB'), ('any', 'DT'), ('person', 'NN'), ('(', '('), ('11', 'CD'), (',', ','), ('12', 'CD'), (',', ','), ('13', 'CD'), (')', ')'), ('.', '.'), ('King', 'VBG'), ('Uparicharvasu', 'NNP'), (',', ','), ('even', 'RB'), ('though', 'IN'), ('he', 'PRP'), ('ruled', 'VBD'), ('the', 'DT'), ('whole', 'JJ'), ('world', 'NN'), (',', ','), ('practiced', 'VBD'), ('ahimsa', 'NN'), ('.', '.'), ('Shriji', 'NNP'), ('Maharaj', 'NNP'), ('has', 'VBZ'), ('explained', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('Vachanamrut', 'NNP'), ('that', 'IN'), ('non-violence', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('dharma', 'NN'), ('by', 'IN'), ('which', 'WDT'), ('one', 'NN'), ('is', 'VBZ'), ('led', 'VBN'), ('to', 'TO'), ('liberation', 'NN'), ('(', '('), ('Vachanamrut', 'NNP'), ('Gadhada', 'NNP'), ('I-69', 'NNP'), (')', ')'), ('.', '.'), ('Harsh', 'NNP'), ('words', 'NNS'), ('which', 'WDT'), ('create', 'VBP'), ('mental', 'JJ'), ('pain', 'NN'), ('also', 'RB'), ('tantamount', 'NN'), ('to', 'TO'), ('himsa', 'VB'), ('.', '.'), ('Always', 'NNP'), ('speak', 'VBP'), ('in', 'IN'), ('a', 'DT'), ('truthful', 'JJ'), (',', ','), ('loving', 'VBG'), ('and', 'CC'), ('beneficial', 'JJ'), ('manner', 'NN'), ('.', '.'), ('Never', 'NNP'), ('speak', 'VBP'), ('untruth', 'JJ'), ('.', '.'), ('One', 'CD'), ('should', 'MD'), ('never', 'RB'), ('tell', 'VB'), ('a', 'DT'), ('lie', 'NN'), ('even', 'RB'), ('for', 'IN'), ('financial', 'JJ'), ('or', 'CC'), ('other', 'JJ'), ('gains', 'NNS'), ('.', '.'), ('One', 'CD'), ('should', 'MD'), ('never', 'RB'), ('utter', 'VB'), ('truth', 'NN'), ('which', 'WDT'), ('may', 'MD'), ('cause', 'VB'), ('danger', 'NN'), ('to', 'TO'), ('one', 'CD'), ('’', 'NN'), ('s', 'JJ'), ('life', 'NN'), ('or', 'CC'), ('to', 'TO'), ('another', 'DT'), ('’', 'NN'), ('s', 'NN'), ('.', '.'), ('For', 'IN'), ('example', 'NN'), (',', ','), ('if', 'IN'), ('a', 'DT'), ('butcher', 'NN'), ('chasing', 'VBG'), ('a', 'DT'), ('cow', 'NN'), ('to', 'TO'), ('kill', 'VB'), ('it', 'PRP'), ('asks', 'VBZ'), (',', ','), ('“', 'NN'), ('Where', 'NNP'), ('has', 'VBZ'), ('the', 'DT'), ('cow', 'NN'), ('gone', 'VBN'), ('?', '.'), ('”', 'VB'), ('one', 'CD'), ('should', 'MD'), ('tell', 'VB'), ('a', 'DT'), ('lie', 'NN'), ('to', 'TO'), ('save', 'VB'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('the', 'DT'), ('cow', 'NN'), ('.', '.')]\n",
            "(S\n",
            "  (GPE Ahimsa/NNP)\n",
            "  paramo/NN\n",
            "  dharmaha/NN\n",
            "  ’/NNP\n",
            "  –/NNP\n",
            "  Non-violence/NNP\n",
            "  is/VBZ\n",
            "  the/DT\n",
            "  highest/JJS\n",
            "  ethical/JJ\n",
            "  code/NN\n",
            "  laid/VBD\n",
            "  down/RB\n",
            "  in/IN\n",
            "  all/PDT\n",
            "  the/DT\n",
            "  shastras/NNS\n",
            "  ./.\n",
            "  No/DT\n",
            "  one/NN\n",
            "  should/MD\n",
            "  harm/VB\n",
            "  any/DT\n",
            "  creature/NN\n",
            "  by/IN\n",
            "  body/NN\n",
            "  ,/,\n",
            "  mind/NN\n",
            "  or/CC\n",
            "  speech/NN\n",
            "  ;/:\n",
            "  nor/CC\n",
            "  should/MD\n",
            "  anyone/NN\n",
            "  intentionally/RB\n",
            "  kill/VB\n",
            "  insects/NNS\n",
            "  such/JJ\n",
            "  as/IN\n",
            "  lice/NN\n",
            "  ,/,\n",
            "  bugs/NNS\n",
            "  ,/,\n",
            "  etc/FW\n",
            "  ./.\n",
            "  Even/RB\n",
            "  for/IN\n",
            "  the/DT\n",
            "  purpose/NN\n",
            "  of/IN\n",
            "  performing/VBG\n",
            "  yagnas/NNS\n",
            "  ,/,\n",
            "  none/NN\n",
            "  should/MD\n",
            "  kill/VB\n",
            "  animals/NNS\n",
            "  ./.\n",
            "  This/DT\n",
            "  is/VBZ\n",
            "  because/IN\n",
            "  it/PRP\n",
            "  is/VBZ\n",
            "  a/DT\n",
            "  sin/NN\n",
            "  to/TO\n",
            "  kill/VB\n",
            "  animals/NNS\n",
            "  and/CC\n",
            "  offer/VB\n",
            "  them/PRP\n",
            "  as/IN\n",
            "  sacrifices/NNS\n",
            "  ./.\n",
            "  (PERSON Shriji/NNP Maharaj/NNP)\n",
            "  even/RB\n",
            "  refused/VBD\n",
            "  to/TO\n",
            "  pluck/VB\n",
            "  spinach/NN\n",
            "  leaves/NNS\n",
            "  in/IN\n",
            "  (GPE Jagannathpuri/NNP)\n",
            "  on/IN\n",
            "  the/DT\n",
            "  grounds/NNS\n",
            "  that/IN\n",
            "  it/PRP\n",
            "  also/RB\n",
            "  has/VBZ\n",
            "  life/NN\n",
            "  ./.\n",
            "  Even/RB\n",
            "  for/IN\n",
            "  women/NNS\n",
            "  ,/,\n",
            "  wealth/NN\n",
            "  or/CC\n",
            "  kingdom/NN\n",
            "  ,/,\n",
            "  one/CD\n",
            "  should/MD\n",
            "  never/RB\n",
            "  ,/,\n",
            "  in/IN\n",
            "  any/DT\n",
            "  way/NN\n",
            "  ,/,\n",
            "  harm/NN\n",
            "  or/CC\n",
            "  kill/VB\n",
            "  any/DT\n",
            "  person/NN\n",
            "  (/(\n",
            "  11/CD\n",
            "  ,/,\n",
            "  12/CD\n",
            "  ,/,\n",
            "  13/CD\n",
            "  )/)\n",
            "  ./.\n",
            "  King/VBG\n",
            "  (GPE Uparicharvasu/NNP)\n",
            "  ,/,\n",
            "  even/RB\n",
            "  though/IN\n",
            "  he/PRP\n",
            "  ruled/VBD\n",
            "  the/DT\n",
            "  whole/JJ\n",
            "  world/NN\n",
            "  ,/,\n",
            "  practiced/VBD\n",
            "  ahimsa/NN\n",
            "  ./.\n",
            "  (PERSON Shriji/NNP Maharaj/NNP)\n",
            "  has/VBZ\n",
            "  explained/VBN\n",
            "  in/IN\n",
            "  the/DT\n",
            "  Vachanamrut/NNP\n",
            "  that/IN\n",
            "  non-violence/NN\n",
            "  is/VBZ\n",
            "  the/DT\n",
            "  dharma/NN\n",
            "  by/IN\n",
            "  which/WDT\n",
            "  one/NN\n",
            "  is/VBZ\n",
            "  led/VBN\n",
            "  to/TO\n",
            "  liberation/NN\n",
            "  (/(\n",
            "  (ORGANIZATION Vachanamrut/NNP Gadhada/NNP)\n",
            "  I-69/NNP\n",
            "  )/)\n",
            "  ./.\n",
            "  (PERSON Harsh/NNP)\n",
            "  words/NNS\n",
            "  which/WDT\n",
            "  create/VBP\n",
            "  mental/JJ\n",
            "  pain/NN\n",
            "  also/RB\n",
            "  tantamount/NN\n",
            "  to/TO\n",
            "  himsa/VB\n",
            "  ./.\n",
            "  Always/NNP\n",
            "  speak/VBP\n",
            "  in/IN\n",
            "  a/DT\n",
            "  truthful/JJ\n",
            "  ,/,\n",
            "  loving/VBG\n",
            "  and/CC\n",
            "  beneficial/JJ\n",
            "  manner/NN\n",
            "  ./.\n",
            "  Never/NNP\n",
            "  speak/VBP\n",
            "  untruth/JJ\n",
            "  ./.\n",
            "  One/CD\n",
            "  should/MD\n",
            "  never/RB\n",
            "  tell/VB\n",
            "  a/DT\n",
            "  lie/NN\n",
            "  even/RB\n",
            "  for/IN\n",
            "  financial/JJ\n",
            "  or/CC\n",
            "  other/JJ\n",
            "  gains/NNS\n",
            "  ./.\n",
            "  One/CD\n",
            "  should/MD\n",
            "  never/RB\n",
            "  utter/VB\n",
            "  truth/NN\n",
            "  which/WDT\n",
            "  may/MD\n",
            "  cause/VB\n",
            "  danger/NN\n",
            "  to/TO\n",
            "  one/CD\n",
            "  ’/NN\n",
            "  s/JJ\n",
            "  life/NN\n",
            "  or/CC\n",
            "  to/TO\n",
            "  another/DT\n",
            "  ’/NN\n",
            "  s/NN\n",
            "  ./.\n",
            "  For/IN\n",
            "  example/NN\n",
            "  ,/,\n",
            "  if/IN\n",
            "  a/DT\n",
            "  butcher/NN\n",
            "  chasing/VBG\n",
            "  a/DT\n",
            "  cow/NN\n",
            "  to/TO\n",
            "  kill/VB\n",
            "  it/PRP\n",
            "  asks/VBZ\n",
            "  ,/,\n",
            "  “/NN\n",
            "  (PERSON Where/NNP)\n",
            "  has/VBZ\n",
            "  the/DT\n",
            "  cow/NN\n",
            "  gone/VBN\n",
            "  ?/.\n",
            "  ”/VB\n",
            "  one/CD\n",
            "  should/MD\n",
            "  tell/VB\n",
            "  a/DT\n",
            "  lie/NN\n",
            "  to/TO\n",
            "  save/VB\n",
            "  the/DT\n",
            "  life/NN\n",
            "  of/IN\n",
            "  the/DT\n",
            "  cow/NN\n",
            "  ./.)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# This code has 2 custom paragraph that is taken from a book called Kishor Satsang Pravesh from BAPS Sanstha, which is used for tokenization.\n",
        "# The following code will convert each word into a token and it would pass to pos_tag function which will tag each token and print them.\n",
        "# The nltk.ne_chunk() function that is already a pre-trained classifier will recognize the named entity using POS tag done above.\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "from nltk import word_tokenize,pos_tag\n",
        "\n",
        "text = \"\"\"Ahimsa paramo dharmaha’ – Non-violence is the highest ethical code laid down in all the shastras. No one should harm any creature\n",
        "by body, mind or speech; nor should anyone intentionally kill insects such as lice, bugs, etc. Even for the purpose of performing\n",
        "yagnas, none should kill animals. This is because it is a sin to kill animals and offer them as sacrifices. Shriji Maharaj even refused to\n",
        "pluck spinach leaves in Jagannathpuri on the grounds that it also has life. Even for women, wealth or kingdom, one should never, in\n",
        "any way, harm or kill any person (11, 12, 13). King Uparicharvasu, even though he ruled the whole world, practiced ahimsa. Shriji\n",
        "Maharaj has explained in the Vachanamrut that non-violence is the dharma by which one is led to liberation (Vachanamrut Gadhada\n",
        "I-69). Harsh words which create mental pain also tantamount to himsa.\n",
        "Always speak in a truthful, loving and beneficial manner. Never speak untruth. One should never tell a lie even for financial or other\n",
        "gains. One should never utter truth which may cause danger to one’s life or to another’s. For example, if a butcher chasing a cow\n",
        "to kill it asks, “Where has the cow gone?” one should tell a lie to save the life of the cow.\n",
        "\"\"\"\n",
        "tokens = word_tokenize(text)\n",
        "tag=pos_tag(tokens)\n",
        "print(tag)\n",
        "\n",
        "ne_tree = nltk.ne_chunk(tag)\n",
        "print(ne_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d0tL0Df7gCTG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0tL0Df7gCTG",
        "outputId": "f7ade199-07a7-4d82-8e50-bea354a7d647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  O \n",
            "Ahimsa O \n",
            "paramo O \n",
            "dharmaha O \n",
            "’ O \n",
            "– O \n",
            "Non O \n",
            "- O \n",
            "violence O \n",
            "is O \n",
            "the O \n",
            "highest O \n",
            "ethical O \n",
            "code O \n",
            "laid O \n",
            "down O \n",
            "in O \n",
            "all O \n",
            "the O \n",
            "shastras O \n",
            ". O \n",
            "No O \n",
            "one O \n",
            "should O \n",
            "harm O \n",
            "any O \n",
            "creature O \n",
            "\n",
            " O \n",
            "by O \n",
            "body O \n",
            ", O \n",
            "mind O \n",
            "or O \n",
            "speech O \n",
            "; O \n",
            "nor O \n",
            "should O \n",
            "anyone O \n",
            "intentionally O \n",
            "kill O \n",
            "insects O \n",
            "such O \n",
            "as O \n",
            "lice O \n",
            ", O \n",
            "bugs O \n",
            ", O \n",
            "etc O \n",
            ". O \n",
            "Even O \n",
            "for O \n",
            "the O \n",
            "purpose O \n",
            "of O \n",
            "performing O \n",
            "\n",
            " O \n",
            "yagnas O \n",
            ", O \n",
            "none O \n",
            "should O \n",
            "kill O \n",
            "animals O \n",
            ". O \n",
            "This O \n",
            "is O \n",
            "because O \n",
            "it O \n",
            "is O \n",
            "a O \n",
            "sin O \n",
            "to O \n",
            "kill O \n",
            "animals O \n",
            "and O \n",
            "offer O \n",
            "them O \n",
            "as O \n",
            "sacrifices O \n",
            ". O \n",
            "Shriji B PERSON\n",
            "Maharaj I PERSON\n",
            "even O \n",
            "refused O \n",
            "to O \n",
            "\n",
            " O \n",
            "pluck O \n",
            "spinach O \n",
            "leaves O \n",
            "in O \n",
            "Jagannathpuri B GPE\n",
            "on O \n",
            "the O \n",
            "grounds O \n",
            "that O \n",
            "it O \n",
            "also O \n",
            "has O \n",
            "life O \n",
            ". O \n",
            "Even O \n",
            "for O \n",
            "women O \n",
            ", O \n",
            "wealth O \n",
            "or O \n",
            "kingdom O \n",
            ", O \n",
            "one O \n",
            "should O \n",
            "never O \n",
            ", O \n",
            "in O \n",
            "\n",
            " O \n",
            "any O \n",
            "way O \n",
            ", O \n",
            "harm O \n",
            "or O \n",
            "kill O \n",
            "any O \n",
            "person O \n",
            "( O \n",
            "11 B CARDINAL\n",
            ", O \n",
            "12 B DATE\n",
            ", O \n",
            "13 B CARDINAL\n",
            ") O \n",
            ". O \n",
            "King O \n",
            "Uparicharvasu B ORG\n",
            ", O \n",
            "even O \n",
            "though O \n",
            "he O \n",
            "ruled O \n",
            "the O \n",
            "whole O \n",
            "world O \n",
            ", O \n",
            "practiced O \n",
            "ahimsa O \n",
            ". O \n",
            "Shriji O \n",
            "\n",
            " O \n",
            "Maharaj B ORG\n",
            "has O \n",
            "explained O \n",
            "in O \n",
            "the O \n",
            "Vachanamrut B NORP\n",
            "that O \n",
            "non O \n",
            "- O \n",
            "violence O \n",
            "is O \n",
            "the O \n",
            "dharma O \n",
            "by O \n",
            "which O \n",
            "one O \n",
            "is O \n",
            "led O \n",
            "to O \n",
            "liberation O \n",
            "( O \n",
            "Vachanamrut B PERSON\n",
            "Gadhada I PERSON\n",
            "\n",
            " O \n",
            "I-69 B PRODUCT\n",
            ") O \n",
            ". O \n",
            "Harsh B ORG\n",
            "words O \n",
            "which O \n",
            "create O \n",
            "mental O \n",
            "pain O \n",
            "also O \n",
            "tantamount O \n",
            "to O \n",
            "himsa O \n",
            ". O \n",
            "\n",
            " O \n",
            "Always O \n",
            "speak O \n",
            "in O \n",
            "a O \n",
            "truthful O \n",
            ", O \n",
            "loving O \n",
            "and O \n",
            "beneficial O \n",
            "manner O \n",
            ". O \n",
            "Never O \n",
            "speak O \n",
            "untruth O \n",
            ". O \n",
            "One B CARDINAL\n",
            "should O \n",
            "never O \n",
            "tell O \n",
            "a O \n",
            "lie O \n",
            "even O \n",
            "for O \n",
            "financial O \n",
            "or O \n",
            "other O \n",
            "\n",
            " O \n",
            "gains O \n",
            ". O \n",
            "One B CARDINAL\n",
            "should O \n",
            "never O \n",
            "utter O \n",
            "truth O \n",
            "which O \n",
            "may O \n",
            "cause O \n",
            "danger O \n",
            "to O \n",
            "one O \n",
            "’s O \n",
            "life O \n",
            "or O \n",
            "to O \n",
            "another O \n",
            "’s O \n",
            ". O \n",
            "For O \n",
            "example O \n",
            ", O \n",
            "if O \n",
            "a O \n",
            "butcher O \n",
            "chasing O \n",
            "a O \n",
            "cow O \n",
            "\n",
            " O \n",
            "to O \n",
            "kill O \n",
            "it O \n",
            "asks O \n",
            ", O \n",
            "“ O \n",
            "Where O \n",
            "has O \n",
            "the O \n",
            "cow O \n",
            "gone O \n",
            "? O \n",
            "” O \n",
            "one O \n",
            "should O \n",
            "tell O \n",
            "a O \n",
            "lie O \n",
            "to O \n",
            "save O \n",
            "the O \n",
            "life O \n",
            "of O \n",
            "the O \n",
            "cow O \n",
            ". O \n"
          ]
        }
      ],
      "source": [
        "# This code has 2 custom paragraph that is taken from a book called Kishor Satsang Pravesh from BAPS Sanstha, which is used for tokenization.\n",
        "# The following code will perform the tokenization and print the token entity annotations, and the entity types of the token.\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"\"\" Ahimsa paramo dharmaha’ – Non-violence is the highest ethical code laid down in all the shastras. No one should harm any creature\n",
        "by body, mind or speech; nor should anyone intentionally kill insects such as lice, bugs, etc. Even for the purpose of performing\n",
        "yagnas, none should kill animals. This is because it is a sin to kill animals and offer them as sacrifices. Shriji Maharaj even refused to\n",
        "pluck spinach leaves in Jagannathpuri on the grounds that it also has life. Even for women, wealth or kingdom, one should never, in\n",
        "any way, harm or kill any person (11, 12, 13). King Uparicharvasu, even though he ruled the whole world, practiced ahimsa. Shriji\n",
        "Maharaj has explained in the Vachanamrut that non-violence is the dharma by which one is led to liberation (Vachanamrut Gadhada\n",
        "I-69). Harsh words which create mental pain also tantamount to himsa.\n",
        "Always speak in a truthful, loving and beneficial manner. Never speak untruth. One should never tell a lie even for financial or other\n",
        "gains. One should never utter truth which may cause danger to one’s life or to another’s. For example, if a butcher chasing a cow\n",
        "to kill it asks, “Where has the cow gone?” one should tell a lie to save the life of the cow.\"\"\")\n",
        "for token in doc:\n",
        "    print(token.text, token.ent_iob_, token.ent_type_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LGxyJO1BgecR",
      "metadata": {
        "id": "LGxyJO1BgecR"
      },
      "source": [
        "The following code perform the tokenization and print the token entity annotations, and the entity types of the token. It did a good job in tokenization each and every word in the paragraph but it was a bit difficult for the model to identiy the entities in the paragraph as it. Still it did a descent work and gave a nearby good results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wJXT_tfUhGkv",
      "metadata": {
        "id": "wJXT_tfUhGkv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
